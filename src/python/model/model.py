import csv
import pandas as pd
import numpy as np
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr
import scipy.stats as stats
import sys
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA


class model(object):

	'''
	Args:
		dataset - path to dataset
		top_genes - path to top genes file
	**kwargs
		genes_list - path to genes list generated by callR_for_genes
				   - False if new_features file is already ready for input

		new_features - path to new features file

	'''
	def __init__(self, dataset, risk_genes, **kwargs):

		print('Loading dataset...')
		# args
		self.dataset = pd.read_csv(dataset, compression = 'gzip')
		self.labels = self.dataset['labels']
		self.dataset = self.dataset.drop('labels', axis = 1)
		self.dataset = self.dataset.drop(self.dataset.columns[0], axis = 1)

		self.risk_genes = pd.read_csv(risk_genes, sep = ';')
		self.risk_genes = set(self.risk_genes['Locus'])

		# **kwargs
		if 'genes_list' in kwargs:
			
			with open(kwargs.get('genes_list'), 'r') as file:
				reader = csv.reader(file)
				genes_list = list(reader)
			
			setattr(self, 'genes_list', genes_list)
			self.genes_list = self.genes_list[0]

		else:
			self.genes_list = None


	# find SNP's of important regions
	def topGenes(self):

		variants = list(self.dataset)
		print(len(variants))

		if not (self.genes_list):
			self.genes_list = self.callR_for_genes(variants)
			self.genes_list = self.genes_list[0]

		self.genes_list = [str.replace('“','') for str in self.genes_list]
		self.genes_list = [str.replace('”','') for str in self.genes_list]

		print(len(self.genes_list))

		print('Building genes dictionary...')
		genes_dict = {}
		for index, gene in enumerate(self.genes_list):
			if gene in genes_dict.keys():
				genes_dict[gene].append(variants[index])
			else:
				genes_dict[gene] = []
				genes_dict[gene].append(variants[index])

		# get chi-squared for every variant
		print('Computing chi-squared')
		chisquared_dict = self.chi_square_for_all()
		#print(chisquared_dict)
		print(genes_dict)

		# Group top regions (with chi square) and risk regions and extract features from them
		# The remaining regions will be the risk ones and the ones with chi-squared average less than 0.05, 0.005 or 0.005
		print('Building top regions dataset...')
		new_dataset = pd.DataFrame()
		for index, gene in enumerate(self.risk_genes):

			if gene in genes_dict:

				new_features = self.feature_extraction(genes_dict[gene], gene)
				new_dataset = pd.concat([new_dataset, new_features], axis=1)
				del genes_dict[gene]

			sys.stdout.write('\r')
			to_finish = 100 * index/len(self.risk_genes)
			sys.stdout.write("%.2f" % to_finish + '%')
			#sys.stdout.write('Memory usage:' + str(process.memory_info().rss/1000000) + 'MB')
			sys.stdout.flush()

		#print(new_dataset)
		print("Building regions signaled by chi-squared...")

		# All the Nones or "" will not be considered
		# get variants key and compute mean(chi-square)
		for index, gene in enumerate(genes_dict.keys()):

			chi_pval_mean = []
			for variant in genes_dict[gene]: 

				pval = chisquared_dict[variant]
				pval = pval[1]
				chi_pval_mean.append(pval)

			temp_chi_mean = sum(chi_pval_mean) / len(chi_pval_mean)

			if temp_chi_mean < 0.05:

				new_features = self.feature_extraction(genes_dict[gene], gene)
				new_dataset = pd.concat([new_dataset, new_features], axis=1)

			sys.stdout.write('\r')
			to_finish = 100 * index/len(genes_dict)
			sys.stdout.write("%.2f" % to_finish + '%')
			#sys.stdout.write('Memory usage:' + str(process.memory_info().rss/1000000) + 'MB')
			sys.stdout.flush()

		new_dataset = pd.concat([new_dataset, self.labels], axis = 1)
		print(new_dataset.head())
		new_dataset.to_csv('../../../data/full_dataset/full_data_new_features.csv')


	def feature_extraction(self, variants_list, gene_name):

		# Extracting a few features
		# LDA, PCA, Variance, Mean
		new_features = pd.DataFrame()

		#print("Computing LDA...")
		lda = LinearDiscriminantAnalysis(n_components=1)
		X_lda = lda.fit(self.dataset[variants_list], self.labels).transform(self.dataset[variants_list])
		#print(X_lda)

		pca = PCA(n_components=1)
		X_pca = pca.fit(self.dataset[variants_list]).transform(self.dataset[variants_list])
		#print(X_pca)

		#print("Computing Mean and Variance by row...")
		mean = []
		variance = []
		for index, row in self.dataset[variants_list].iterrows():

			temp_mean = sum(row) / len(row)
			mean.append(temp_mean)
			variance.append(sum((xi - temp_mean) ** 2 for xi in row) / len(row))

		X_pca = [comp[0] for comp in X_pca]

		new_features[str(gene_name) + "_PCA"] = X_pca
		new_features[str(gene_name) + "_LDA"] = X_lda
		new_features[str(gene_name) + "_mean"] = mean
		new_features[str(gene_name) + "_variance"] = variance

		return(new_features)


	def chi_square_for_all(self):

		chisquared_dict = {}
		dataset_len = len(list(self.dataset))
		for index, variant in enumerate(list(self.dataset)):
			# Making contigency table (GTs_no x 2)  
			table = pd.crosstab(self.dataset[variant], self.labels)
			table = table.loc[:, [0, 1]]

			chi2, p, dof, ex = stats.chi2_contingency(table, correction = False)
			chisquared_dict[variant] = [chi2, p]

			sys.stdout.write('\r')
			to_finish = 100 * index/dataset_len
			sys.stdout.write("%.2f" % to_finish + '%')
			#sys.stdout.write('Memory usage:' + str(process.memory_info().rss/1000000) + 'MB')
			sys.stdout.flush()

		return(chisquared_dict)


	# variants - variants list
	def callR_for_genes(self, variants):

		print('Calling R for genes...')

		r = robjects.r
		r['source']("../../R/geneRetriever.R")
		genes_list = r.chr_to_gene(variants)

		print(genes_list)

		with open('../../../data/knownvariants/genes_list.csv', 'w') as genes_file:
			wr = csv.writer(genes_file, quoting=csv.QUOTE_ALL)
			wr.writerow(genes_list)

		return(genes_list)

